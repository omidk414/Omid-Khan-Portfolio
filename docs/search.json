[
  {
    "objectID": "work_experience.html",
    "href": "work_experience.html",
    "title": "Professional Experience",
    "section": "",
    "text": "My Career Journey:\n\nJunior Data Engineer (I.T Services | Digital & Product Solutions)\n\nApril 2023 - Present\nAgile Datapro [Microsoft ISV Partner], Campbell, CA\n\nIP Product Project (Azure, Python, BlobStorage, ChatGPT 4 Turbo Key API, AI/ML, Jupyter Notebooks, Outlook, Pandas, REST, Excel):\n\nWeb scrapped several sites using a Python script with Selenium API, efficiently extracting 250k resumes from Outlook, achieving a consistent average of 100 job listings per minute, and collecting an extensive dataset of over 20k job listings weekly from various websites.\nAutomated data extraction processes, resulting in saving of over 80 hours each month, significantly improving productivity and data collection rates.\nOrganized and structured large amounts of data in XLSX format; encompassing attributes such as job titles, company names, locations, detailed job descriptions, and salary information.\nEnsured quality data extraction and consistency, reducing data preparation time by 70%, facilitating efficient data analysis, and reporting.\nImplemented data storage procedures, efficiently saving collected data to XLSX files, including a system that dynamically checks and adds missing headers to enhance data management efficiency and eliminate potential errors.\nCreated data transfer pipelines to Blob Storage, delivering a 85% reduction in manual data entry errors.\nConducted data preprocessing, systematically removing duplicates, and efficiently categorizing data by industry buckets, enhancing data quality by 80%.\nParsed and extracted critical information, including names, job titles, emails, resume contents, and top 5 skills from each resume to train the ML model and in order to generate score cards.\nAutomated scorecard generation, which resulted in 50% reduction in manual effort and saving approximately 15 hours per project cycle.\nTailored each score card with personalized information, including names, skills, and skill percentages, maintaining an accuracy rate of 95% in reflecting candidate profiles and skills.\nAssisted in training the ML model to provide job recommendations and candidates, streamlining the hiring process and improved candidate matches.  \n\nTelecom Project (GCP, Python, SQL, PostgreSQL, PowerBI, Docker, ChatGPT 3.5 Turbo Key API, AI/ML, Jupyter Notebooks, Flask):\n\nDeveloped predictive models for a major telecom client to predict cost, utilization or social health, and deployed them on Google Cloud Platform.\nUtilized client staging environment to extract consumer data in JSON format for analysis and processing.\nIntegrated ChatGPT API to the GCP on a PowerBI dashboard. Allows users to ask the chatbot about their multi-tenant dashboard content, issues, etc.\nBuilt the chatbot using Microsoft Virtual Agent (interface for chatbot), and that Agent had an automated flow using Power Automate.\nConducted and drove the adoption of enterprise-wide analytics to support strategic execution using prescriptive and predictive analytics with a specialty in the Finance, Quality and Utilization domains.\nCreated visually appealing dashboards for data analysis and visualization using BI and PostgreSQL.\nTailored the dashboards to meet client requirements and presented complex data sets in a clear and concise manner.\nDeveloped interactive, meaningful and user-friendly dashboards to enable quick identification of key insights and trends.\nEnsured scalability of dashboards to accommodate additional data.\nCompiled hyperparameter tuning pipelines for AI/machine learning and deep learning models. The framework enabled the company to train and deploy machine learning models 2 times faster, resulting in a 25% improvement in prediction accuracy.\n \n\nAIoT Project (Python, Raspberry PI, OpenCV, Tensorflow, Keras):\n\nDesigned an AIOT solution to an client that created an online platform to teach programming in the classroom for over 50 colleges in India.\nDeveloped object detection and recognition modules for a manufacturing facility, resulting in a 40% reduction in manual labor and a 20% increase in operational efficiency.\nObtained data sets off Kaggle, and GitHub repositories to train the model.\nCreated an ETL pipeline using Python, and preprocessed the data to find null values.\nCollaborated on the integration of IR sensors for real-time object recognition and tracking, streamlining manufacturing processes and improving productivity.\nAssisted in the design and implementation of an ultrasonic sensor module for precise object placement, achieving a 15% reduction in errors.\nUtilized advanced data science techniques to analyze sensor data, leading to a 25% reduction in equipment downtime.\nTrained object detection models using Keras and TensorFlow, enabling the system to detect objects and display their coordinates, colors, and shapes accurately.\nUtilized data science techniques to analyze sensor data, identifying patterns and anomalies for predictive maintenance, resulting in a 15% decrease in equipment downtime.\nPerformed thorough testing and validation of the sensor modules, ensuring accuracy, reliability, and seamless integration into the clients platform.  \n\nData Science and Machine Learning Intern (Ascend Technology Inc.)\n\nJan 2022 - May 2022\n1879 Lundy Ave STE 289, San Jose, CA 95131\nResearch Mentors: Dr. Mokhtar Sadok, Dr. Indranil Mukhopadhyay, Dr. Mohammad Akram Hossain\nGitHub Repository: NeuroScan\n\nProject Title: “NeuroScan” – Machine Learning Application for Brain Tumor Detection\nTechnologies: Python, TensorFlow, Keras, OpenCV, Jupyter Notebooks\n\nCollaborated with Dr. Mokhtar Sadok, Dr. Indranil Mukhopadhyay, and Dr. Mohammad Akram Hossain to develop “NeuroScan,” a machine learning application designed for brain tumor detection.\nConducted extensive research on medical imaging datasets, including MRI scans, to identify features and patterns indicative of brain tumors.\nUtilized machine learning algorithms such as Convolutional Neural Networks (CNNs) and Support Vector Machines (SVMs) with Python and TensorFlow to analyze and classify brain images, achieving high accuracy rates.\nLed efforts in preprocessing and cleaning datasets to ensure robust and accurate models for tumor detection.\nWorked closely with medical professionals to validate and refine the model’s performance, incorporating feedback to enhance precision and sensitivity.\nPresented the project’s progress and findings in departmental seminars, showcasing technical skills and the ability to communicate complex concepts effectively.\n\nCitations:\n\nSadok, M. (2021, August 8). Artificial Intelligence: A paradigm shift in the pharmaceutical industry - use case of cancer detection. Digitale Transformation - jetzt die Chancen aktiv nutzen! https://www.strategy-transformation.com/artificial-intelligence-a-paradigm-shift-in-the-pharmaceutical-industry-use-case-of-cancer-detection/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "As a passionate software engineer, my goals include:\n\nLeveraging technology to drive actionable insights from data.\nBuilding innovative and efficient solutions to real-world problems.\nCollaborating with like-minded professionals to achieve excellence.\n\n\n\n\nI hold a Bachelor of Science in Computer Science from California State University, East Bay, where I excelled in courses like:\n\nSoftware Engineering\nData Structures & Algorithms\nOperating Systems\nComputer Architecture\nObject-Oriented Programming\n\nThis robust education has equipped me with a versatile skill set, enabling me to tackle complex software engineering challenges with confidence.\nThanks for checking out my portfolio!\nHover over this text: P I C"
  },
  {
    "objectID": "index.html#goals",
    "href": "index.html#goals",
    "title": "About Me",
    "section": "",
    "text": "As a passionate software engineer, my goals include:\n\nLeveraging technology to drive actionable insights from data.\nBuilding innovative and efficient solutions to real-world problems.\nCollaborating with like-minded professionals to achieve excellence."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "About Me",
    "section": "",
    "text": "I hold a Bachelor of Science in Computer Science from California State University, East Bay, where I excelled in courses like:\n\nSoftware Engineering\nData Structures & Algorithms\nOperating Systems\nComputer Architecture\nObject-Oriented Programming\n\nThis robust education has equipped me with a versatile skill set, enabling me to tackle complex software engineering challenges with confidence."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Here are some of the projects I’ve created:"
  },
  {
    "objectID": "projects.html#projects",
    "href": "projects.html#projects",
    "title": "Projects",
    "section": "Projects",
    "text": "Projects\n\nMachine Learning Project - Image Classification using Convolutional Neural Networks (Python, TensorFlow, Keras, OpenCV, Jupyter Notebooks)\n\nDate: May 2023\nGitHub Repository\nDescription:\n\nDeveloped and implemented an image classification system achieving an accuracy of 70.34% on the CIFAR-10 dataset, accurately classifying a range of 10 different classes.\nDesigned and trained a Convolutional Neural Network model utilizing TensorFlow and Keras, leveraging functions such as Conv2D, MaxPooling2D, and Dense layers to optimize the model for image classification tasks.\nEmployed effective data preprocessing techniques, resulting in a significant improvement of 10% in accuracy compared to the baseline performance.\nApplied advanced techniques, including data augmentation and hyperparameter tuning, which successfully reduced overfitting by 15% and improved the model’s generalization capability.\nCommunicated project findings through detailed documentation and insightful visualizations, showcasing the model’s performance metrics such as accuracy, precision, and recall.\nConducted thorough exploratory data analysis, gaining valuable insights into the dataset and presenting outcomes to stakeholders, highlighting the impact and value of the image classification system.  \n\n\nIoT Project - Knock Sensor (Python, Arduino, Flask, pySerial, Smtplib, Twilio)\n\nDate: May 2022\nGitHub Repository\nDescription:\n\nCoded a low-cost, DIY security solution that serves as an alternative to expensive commercial security products. The total cost of the system was $50, which is 50% lower than the cost of a comparable commercial security product.\nAssembled a knock sensor system using Arduino board and knock sensor module, achieving an accuracy rate of 85% in detecting high-pitch volume sounds. Used a percussion sensor as the input and a buzzer as an output along with a micro LED.\nWrote a script in Python using the serial library to activate a micro LED light upon sound detection, achieving a rapid response time of 0.2 seconds and ensuring uninterrupted operation for up to 24 hours.\nIntegrated email and text notifications using SMTP and Twilio services, enabling real-time alerts for detected sounds. Simultaneously sent notifications to up to 5 email addresses and 3 phone numbers with a latency of less than 1 second.\nCreated a Flask web application in a virtual environment to provide a user-friendly interface for system control and monitoring. Added login and signup functionality to manage user access.\nExecuted comprehensive tests ensuring the reliability and accuracy of the system with a success rate of 99%.  \n\n\nIEEE Project - First-Step Company (GitHub, HTML, Markup)\n\nDate: Nov 2021\nGitHub Repository\nDescription:\n\nLed a team of three and effectively started up a nonprofit tech company that follows ethical guidelines in the industry.\nCoordinated research on large companies’ about pages to develop our own criteria for transparency and accessibility.\nEvolved a company wiki page using HTML, Markup to showcase our mission, goals, and team members and documented our work and collaboration using GitHub for efficient and effective teamwork. The use of GitHub allowed our team of three to manage multiple projects simultaneously, resulting in a 40% reduction in turnaround time for deliverables.\nEmphasized the importance of user data transparency and accessible product development in the tech industry.\nImplemented and executed an effective social media strategy, which led to a 40% increase in online engagement and 30% increase in followers on our class page.\nIncorporated customer feedback to improve product design, resulting in a 20% increase in customer retention and loyalty."
  }
]