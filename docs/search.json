[
  {
    "objectID": "work_experience.html",
    "href": "work_experience.html",
    "title": "Professional Experience",
    "section": "",
    "text": "My Career Journey:\n\nJunior Data Engineer (I.T Services | Digital & Product Solutions)\n\nApril 2023 - Present\nAgile Datapro, Campbell, CA\nIP Product Project (Python, BlobStorage, ChatGPT 3.5 Turbo Key, AI/ML, Jupyter Notebooks, Outlook, Pandas, Excel, Email Integration):\n\nSpearheaded web scraping initiatives, efficiently extracting a remarkable 200,000 to 500,000 resumes from Outlook, achieving a consistent average of 100 job listings per minute, and collecting an extensive dataset of over 20,000 job listings weekly from various websites.\nAutomated data extraction processes, resulting in time-saving of over 80 hours each month, significantly improving productivity and data collection rates.\nOrganized and structured large amounts of data, processing and managing around 10,000 job listings per week, encompassing attributes such as job titles, company names, locations, detailed job descriptions, and salary information.\nEnsured quality data extraction and consistency, reducing data preparation time by 70%, facilitating efficient data analysis, and reporting.\nImplemented data storage procedures, efficiently saving collected data to XLSX files, including a system that dynamically checks and adds missing headers to enhance data management efficiency and eliminate potential errors.\nCreated data transfer pipelines to Blob Storage, delivering a remarkable 85% reduction in manual data entry errors, saving over 300 hours annually.\nConducted data preprocessing, systematically removing duplicates, and efficiently categorizing data by industry buckets, ultimately enhancing data quality by 80%.\nParsed and extracted critical information, including names, job titles, emails, resume contents, and top 5 skills from each resume to train the ML model and in order to generate score cards.\nAutomated scorecard generation, achieving a substantial 80% reduction in manual effort and saving approximately 15 hours per project cycle.\nTailored each score card with personalized information, including names, skills, and skill percentages, maintaining an accuracy rate of 100% in reflecting candidate profiles and skills.\nAssisted in training the ML model to provide job recommendations and candidates, which significantly streamlined the hiring process and improved candidate matches.\n\nTelecom Project (Python, SQL, PostgreSQL, PowerBI, Docker, GCP, ChatGPT 3.5 Turbo Key, AI/ML, Jupyter Notebooks):\n\nDeveloped predictive models for a major telecom client to predict cost, utilization or social health, and deployed them on Google Cloud Platform.\nIntegrated ChatGPT AI chatbot to the GCP on the PowerBI dashboard. Allows users to ask the chatbot about their dashboard content, issues, etc.\nBuilt the chatbot using Microsoft Virtual Agent (interface for chatbot), and that Agent had an automated flow using Power Automate.\nConducted and drove the adoption of enterprise-wide analytics to support strategic execution using prescriptive and predictive analytics with a specialty in the Finance, Quality and Utilization domains.\nCreated visually appealing dashboards for data analysis and visualization using BI and PostgreSQL.\nTailored the dashboards to meet client requirements and presented complex data sets in a clear and concise manner.\nDeveloped interactive, meaningful and user-friendly dashboards to enable quick identification of key insights and trends.\nEnsured scalability of dashboards to accommodate additional data.\nCompiled hyperparameter tuning pipelines for AI/machine learning and deep learning models. The framework enabled the company to train and deploy machine learning models 2 times faster, resulting in a 25% improvement in prediction accuracy.\n\nIoT Project (Python, Raspberry PI, OpenCV, Tensorflow, Keras):\n\nDeveloped object detection and recognition modules for a manufacturing facility, resulting in a 40% reduction in manual labor and a 20% increase in operational efficiency.\nObtained data sets off Kaggle, and github repositories to train the model.\nCreated an ETL pipeline in python, and preprocessed the data to find null values.\nCollaborated on the integration of IR sensors for real-time object recognition and tracking, streamlining manufacturing processes and improving productivity.\nAssisted in the design and implementation of an ultrasonic sensor module for precise object placement, achieving a 15% reduction in errors.\nUtilized advanced data science techniques to analyze sensor data, leading to a 25% reduction in equipment downtime.\nTrained object detection models using Keras and TensorFlow, enabling the system to detect objects and display their coordinates, colors, and shapes accurately.\nUtilized data science techniques to analyze sensor data, identifying patterns and anomalies for predictive maintenance, resulting in a 15% decrease in equipment downtime.\nPerformed thorough testing and validation of the sensor modules, ensuring accuracy, reliability, and seamless integration into the client’s platform.\n\n\nRotary Technician / Assembly Technician (R&D & Product Development)\n\nAug 2019 - Aug 2020\nBay Materials LLC, Fremont, CA\n\nAssisted in configuring the Raspberry Pi and IR sensor for monitoring and recording oven temperatures during polymer drying, resulting in enhanced control and reduced temperature variations by 20%.\nOrganized monthly QC inspections on 1000+ mechanical, dimension, and color attributes of Zendura material products and had a 15% reduction in product defects within six months through inspections.\nMaintained accurate records of equipment calibration status and completed an average of 20 in-facility calibrations per month, reducing equipment downtime by 10% and increasing production efficiency by 5%.\nManaged Biostar lab equipment for thermoforming, including maintenance, troubleshooting, and repair, resulting in a 95% uptime rate for the equipment.\nAided in the production, manufacturing, and packaging of 5000 plastic parts per week, contributing to a 10% increase in production output over a three-month period.\nOperated die cutting equipment for an average of 6 hours per day, handling up to 500 rolls of materials per week and processing an average of 2000 parts per week for drying, cleaning, packaging, and heat-sealing."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "As a passionate software engineer, my goals include:\n\nLeveraging technology to drive actionable insights from data.\nBuilding innovative and efficient solutions to real-world problems.\nCollaborating with like-minded professionals to achieve excellence.\n\n\n\n\nI hold a Bachelor of Science in Computer Science from California State University, East Bay, where I excelled in courses like:\n\nData Structures & Algorithms\nOperating Systems\nComputer Architecture\nObject-Oriented Programming\n\nThis robust education has equipped me with a versatile skill set, enabling me to tackle complex software engineering challenges with confidence.\nThanks for checking out my portfolio!"
  },
  {
    "objectID": "index.html#goals",
    "href": "index.html#goals",
    "title": "About Me",
    "section": "",
    "text": "As a passionate software engineer, my goals include:\n\nLeveraging technology to drive actionable insights from data.\nBuilding innovative and efficient solutions to real-world problems.\nCollaborating with like-minded professionals to achieve excellence."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "About Me",
    "section": "",
    "text": "I hold a Bachelor of Science in Computer Science from California State University, East Bay, where I excelled in courses like:\n\nData Structures & Algorithms\nOperating Systems\nComputer Architecture\nObject-Oriented Programming\n\nThis robust education has equipped me with a versatile skill set, enabling me to tackle complex software engineering challenges with confidence."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Here are some of the projects I’ve created:"
  },
  {
    "objectID": "projects.html#projects",
    "href": "projects.html#projects",
    "title": "Projects",
    "section": "Projects",
    "text": "Projects\n\nMachine Learning Project - Image Classification using Convolutional Neural Networks (Python, TensorFlow, Keras, OpenCV, Jupyter Notebooks)\n\nDate: May 2023\nGitHub Repository\nDescription:\n\nDeveloped and implemented an image classification system achieving an accuracy of 70.34% on the CIFAR-10 dataset, accurately classifying a range of 10 different classes.\nDesigned and trained a Convolutional Neural Network model utilizing TensorFlow and Keras, leveraging functions such as Conv2D, MaxPooling2D, and Dense layers to optimize the model for image classification tasks.\nEmployed effective data preprocessing techniques, resulting in a significant improvement of 10% in accuracy compared to the baseline performance.\nApplied advanced techniques, including data augmentation and hyperparameter tuning, which successfully reduced overfitting by 15% and improved the model’s generalization capability.\nCommunicated project findings through detailed documentation and insightful visualizations, showcasing the model’s performance metrics such as accuracy, precision, and recall.\nConducted thorough exploratory data analysis, gaining valuable insights into the dataset and presenting outcomes to stakeholders, highlighting the impact and value of the image classification system.\n\n\nIoT Project - Knock Sensor (Python, Arduino, Flask, pySerial, Smtplib, Twilio)\n\nDate: May 2022\nGitHub Repository\nDescription:\n\nCoded a low-cost, DIY security solution that serves as an alternative to expensive commercial security products. The total cost of the system was $50, which is 50% lower than the cost of a comparable commercial security product.\nAssembled a knock sensor system using Arduino board and knock sensor module, achieving an accuracy rate of 85% in detecting high-pitch volume sounds. Used a percussion sensor as the input and a buzzer as an output along with a micro LED.\nWrote a script in Python using the serial library to activate a micro LED light upon sound detection, achieving a rapid response time of 0.2 seconds and ensuring uninterrupted operation for up to 24 hours.\nIntegrated email and text notifications using SMTP and Twilio services, enabling real-time alerts for detected sounds. Simultaneously sent notifications to up to 5 email addresses and 3 phone numbers with a latency of less than 1 second.\nCreated a Flask web application in a virtual environment to provide a user-friendly interface for system control and monitoring. Added login and signup functionality to manage user access.\nExecuted comprehensive tests ensuring the reliability and accuracy of the system with a success rate of 99%.\n\n\nIEEE Project - First-Step Company (GitHub, HTML, Markup)\n\nDate: Nov 2021\nGitHub Repository\nDescription:\n\nLed a team of three and effectively started up a nonprofit tech company that follows ethical guidelines in the industry.\nCoordinated research on large companies’ about pages to develop our own criteria for transparency and accessibility.\nEvolved a company wiki page using HTML, Markup to showcase our mission, goals, and team members and documented our work and collaboration using GitHub for efficient and effective teamwork. The use of GitHub allowed our team of three to manage multiple projects simultaneously, resulting in a 40% reduction in turnaround time for deliverables.\nEmphasized the importance of user data transparency and accessible product development in the tech industry.\nImplemented and executed an effective social media strategy, which led to a 40% increase in online engagement and 30% increase in followers on our class page.\nIncorporated customer feedback to improve product design, resulting in a 20% increase in customer retention and loyalty."
  }
]